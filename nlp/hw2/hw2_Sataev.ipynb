{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашняя работа по лекции 3\n",
    "\n",
    "## Задание 1\n",
    "**Формула:**\n",
    "\n",
    "$\n",
    "Z = \\text{softmax} \\left( \\frac{Q K^\\top}{\\sqrt{d_k}} \\right) V\n",
    "$\n",
    "\n",
    "**Пояснение:**  \n",
    "Масштабирующий фактор $ \\frac{1}{\\sqrt{d_k}} $ стабилизирует значения, предотвращая слишком большие экспоненты в функции softmax. Это снижает вероятность возникновения градиентного взрыва или затухания при обучении.\n",
    "\n",
    "---\n",
    "\n",
    "## Задание 2\n",
    "**Ответ:**  \n",
    "Позиционные кодировки добавляются к эмбеддингам входных токенов для передачи информации о порядке токенов в последовательности.  \n",
    "Это необходимо, так как механизм самовнимания обрабатывает все токены одновременно и не учитывает их позиционный порядок без этой информации.\n",
    "\n",
    "---\n",
    "\n",
    "## Задание 3\n",
    "**Ответ:**  \n",
    "\n",
    "$\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\text{RNN и LSTM:} & O(T) \\, \\text{(обрабатывают последовательности последовательно).} \\\\ \n",
    "\\text{Трансформеры:} & O(T^2) \\, \\text{(из-за матричных операций } Q K^\\top \\text{).}\n",
    "\\end{array}\n",
    "\\right.\n",
    "$\n",
    "\n",
    "На длинных последовательностях трансформеры менее эффективны по памяти и времени, однако параллельность ускоряет обучение.\n",
    "\n",
    "---\n",
    "\n",
    "## Задание 4\n",
    "**Модификация:**  \n",
    "Использовать разреженные матрицы внимания (sparse attention) или ограничить область внимания (локальное внимание).  \n",
    "\n",
    "**Эффект:**\n",
    "\n",
    "$\n",
    "O(T^2) \\rightarrow O(T \\log T) \\quad \\text{или} \\quad O(T)\n",
    "$\n",
    "\n",
    "**Преимущества:**  \n",
    "- Уменьшение использования памяти.  \n",
    "- Ускорение вычислений.  \n",
    "- Сохранение качества модели на длинных последовательностях, если информация между удаленными токенами не критична."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
